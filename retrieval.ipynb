{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('bbrv2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f6e2000e74d83ab38a7a73c8353776f8595191be383670aed524d2a15b88663d"
   }
  },
  "interpreter": {
   "hash": "f6e2000e74d83ab38a7a73c8353776f8595191be383670aed524d2a15b88663d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# !curl -X GET \"nersc-tbn-6.testbed100.es.net:9200/iperf3*/_search\" | jq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'\u001b[1m\u001b[36m4\u001b[0m\u001b[0m' indexes found!\n",
      "0: iperf3-2021.06.22\n",
      "1: iperf3-2021.06.04\n",
      "2: iperf3-2021.06.06\n",
      "3: iperf3-2021.06.05\n",
      "Found '\u001b[1m\u001b[36m48\u001b[0m\u001b[0m' documents in the current index '\u001b[1m\u001b[36miperf3-2021.06.22\u001b[0m\u001b[0m'\n",
      "Found '\u001b[1m\u001b[36m10\u001b[0m\u001b[0m' documents in the current index '\u001b[1m\u001b[36miperf3-2021.06.04\u001b[0m\u001b[0m'\n",
      "Found '\u001b[1m\u001b[36m2\u001b[0m\u001b[0m' documents in the current index '\u001b[1m\u001b[36miperf3-2021.06.06\u001b[0m\u001b[0m'\n",
      "Found '\u001b[1m\u001b[36m2\u001b[0m\u001b[0m' documents in the current index '\u001b[1m\u001b[36miperf3-2021.06.05\u001b[0m\u001b[0m'\n",
      "Total docs found:  62\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "**\n",
    "** Project Lead: Eashan Adhikarla\n",
    "** Mentor: Ezra Kissel\n",
    "** \n",
    "** Date Created: June 17' 2021\n",
    "** Last Modified: June 22' 2021 \n",
    "**\n",
    "'''\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Create the elasticsearch client\n",
    "HOST = 'nersc-tbn-6.testbed100.es.net'\n",
    "PORT = 9200\n",
    "\n",
    "es = Elasticsearch(host=HOST, port=PORT)\n",
    "\n",
    "\n",
    "class clr:\n",
    "    \"\"\"\n",
    "    Defining colors for the print syntax coloring\n",
    "    \"\"\"\n",
    "    H   = '\\033[35m' # Header\n",
    "    B   = '\\033[94m' # Blue\n",
    "    G   = '\\033[36m' # Green\n",
    "    W   = '\\033[93m' # Warning\n",
    "    F   = '\\033[91m' # Fail\n",
    "    E   = '\\033[0m'  # End \n",
    "    BD  = '\\033[1m'  # Bold\n",
    "    UL  = '\\033[4m'  # Underline\n",
    "\n",
    "\n",
    "class GETTER:\n",
    "    \"\"\"\n",
    "    Get class to get current information about different Indexs\n",
    "    \"\"\"\n",
    "    def __init__(self, term, sum=0):\n",
    "        self.term = term\n",
    "        self.sum = sum\n",
    "\n",
    "    def getIndexList(self, term):\n",
    "        idx=[]\n",
    "        indices_dict = es.indices.get_alias(self.term)\n",
    "        if isinstance(indices_dict, dict) and indices_dict is not None:\n",
    "            print(f\"'{clr.BD}{clr.G}{len(indices_dict)}{clr.E}{clr.E}' indexes found!\")\n",
    "            for k,v in indices_dict.items():\n",
    "                idx.append(k)\n",
    "            return idx\n",
    "        else:\n",
    "            print (f\"{clr.F}Empty dict!{clr.E}\")\n",
    "\n",
    "    def getIndexedDetails(self, indexes):\n",
    "        for i in range(len(indexes)):\n",
    "            result = es.search(index=indexes[i], \n",
    "                            body={\"query\":{\"match_all\":{}}}, \n",
    "                            size=10000,\n",
    "                            )\n",
    "            print(f\"Found '{clr.BD}{clr.G}{result['hits']['total']['value']}{clr.E}{clr.E}' documents in the current index '{clr.BD}{clr.G}{indexes[i]}{clr.E}{clr.E}'\")\n",
    "            \n",
    "            data = [doc for doc in result['hits']['hits']]\n",
    "\n",
    "            self.sum += result['hits']['total']['value']\n",
    "        print(\"Total docs found: \", self.sum)\n",
    "            # # iterate the nested dictionaries inside the [\"hits\"][\"hits\"] list\n",
    "            # for num, doc in enumerate(data):\n",
    "            #     # print (\"DOC ID:\", doc[\"_id\"], \"--->\", doc, type(doc), \"\\n\")\n",
    "                \n",
    "            #     # Use 'iteritems()` instead of 'items()' if using Python 2\n",
    "            #     for key, value in doc.items():\n",
    "            #         print (f\"{clr.B}{key}{clr.E}   ---> {value}\")\n",
    "\n",
    "            #     # print a few spaces between each doc for readability\n",
    "            #     print (\"\\n\\n\")\n",
    "            #     break\n",
    "\n",
    "\n",
    "\n",
    "indexTypes = [\"*\", \"iperf*\", \"jobmeta*\", \"bbrmon*\"]\n",
    "term_ = indexTypes[1]\n",
    "\n",
    "get = GETTER(term_)\n",
    "indexes = get.getIndexList(term_)\n",
    "for e,i in enumerate(indexes):\n",
    "    print(f\"{e}: {i}\")\n",
    "\n",
    "index_response = get.getIndexedDetails(indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.get(index=\"iperf3-2021.06.06\", id=\"uhKs33kBkImc33Nl6K8P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = es.search(index=indexes[0], body={\"query\":{\"match_all\":{}}})\n",
    "# indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = es.search(index=indexes[0], body={\"query\":{\"match_all\":{}}})\n",
    "\n",
    "# hitsList=[]\n",
    "# print(f\"Found {len(result.items())} keys found..\\n\")\n",
    "\n",
    "print(f\"Found '{clr.B}{clr.BD}{result['hits']['total']['value']}{clr.E}{clr.E}' documents in the current index'{clr.B}{clr.BD}{indexes[0]}{clr.E}{clr.E}'\")\n",
    "\n",
    "data = [doc for doc in result['hits']['hits']]\n",
    "\n",
    "i=0\n",
    "print(data[i]['_source'].keys())\n",
    "print(\"\\n\")\n",
    "print(data[i]['_source']['end'])\n",
    "# print(data[i]['_source']['@version'])\n",
    "# print(data[i]['_source']['start'])\n",
    "# print(data[i]['_source']['uuid'])\n",
    "# print(data[i]['_source']['@timestamp'])\n",
    "print()\n",
    "\n",
    "i=1\n",
    "print(data[i]['_source'].keys())\n",
    "print(\"\\n\")\n",
    "print(data[i]['_source']['end'])\n",
    "# print(data[i]['_source']['@version'])\n",
    "# print(data[i]['_source']['start'])\n",
    "# print(data[i]['_source']['uuid'])\n",
    "# print(data[i]['_source']['@timestamp'])\n",
    "print()\n",
    "\n",
    "i=2\n",
    "print(data[i]['_source'].keys())\n",
    "print(\"\\n\")\n",
    "print(data[i]['_source']['end'])\n",
    "# print(data[i]['_source']['@version'])\n",
    "# print(data[i]['_source']['start'])\n",
    "# print(data[i]['_source']['uuid'])\n",
    "# print(data[i]['_source']['@timestamp'])\n",
    "print()\n",
    "\n",
    "# for doc in data:\n",
    "#     print(doc['_source'].keys())\n",
    "#     print(doc['_source']['start'])\n",
    "#     print(doc['_source']['uuid'])\n",
    "#     print(doc['_source']['@timestamp'])\n",
    "#     break\n",
    "    # print(f\"{doc['_id']}, {doc['_source']}\"), {doc['_source']}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k2,v2 in hitsList[0][0].items():\n",
    "    print(k2)\n",
    "    if k2==\"_score\":\n",
    "        for v in value:\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(host='nersc-tbn-6.testbed100.es.net', port=9200)\n",
    "res = es.search(index=\"iperf3*\",\n",
    "                # doc_type=\"articles\",\n",
    "                body={\"query\": \n",
    "                        {\"match\": \n",
    "                                {\"content\": \"\"}\n",
    "                        }\n",
    "                      })\n",
    "print(\"res: \", res)\n",
    "\n",
    "print(f\"{res['hits']['total']} documents found\")\n",
    "\n",
    "for doc in res['hits']['hits']:\n",
    "    print(\"%s) %s\" % (doc['_id'], doc['_source']['content']))\n"
   ]
  },
  {
   "source": [
    "## Querying elasticsearch via elasticsearch-py module"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data_from_elastic():\n",
    "    \n",
    "# query: The elasticsearch query.\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"symbols.keyword\": \"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Scan function to get all the data. \n",
    "rel = scan( client=es,             \n",
    "            query=query,                                     \n",
    "            scroll='1m',\n",
    "            index='iperf3*',\n",
    "            raise_on_error=True,\n",
    "            preserve_order=True,\n",
    "            clear_scroll=True)\n",
    "\n",
    "# Keep response in a list.\n",
    "if not rel==None:\n",
    "    result = list(rel)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# temp = []\n",
    "\n",
    "# # We need only '_source', which has all the fields required.\n",
    "# # This elimantes the elasticsearch metdata like _id, _type, _index.\n",
    "# for hit in result:\n",
    "#     temp.append(hit['_source'])\n",
    "\n",
    "# # Create a dataframe.\n",
    "# df = pd.DataFrame(temp)\n",
    "\n",
    "# return df\n"
   ]
  },
  {
   "source": [
    "## Querying elasticsearch via REST api"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(uri, term):\n",
    "    \"\"\"\n",
    "    Simple Elasticsearch Query\n",
    "    \"\"\"\n",
    "    query = json.dumps({\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"content\": term\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    response = requests.get(uri, data=query)\n",
    "    results = json.loads(response.text)\n",
    "    return results\n",
    "\n",
    "def format_results(results):\n",
    "    \"\"\"\n",
    "    Print results nicely:\n",
    "    doc_id) content\n",
    "    \"\"\"\n",
    "    data = [doc for doc in results['hits']['hits']]\n",
    "    for doc in data:\n",
    "        print(\"%s) %s\" % (doc['_id'], doc['_source']['content']))\n",
    "\n",
    "def create_doc(uri, doc_data={}):\n",
    "    \"\"\"\n",
    "    Create new document.\n",
    "    \"\"\"\n",
    "    query = json.dumps(doc_data)\n",
    "    response = requests.post(uri, data=query)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_data_from_elastic()\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    uri_search = 'http://192.168.120.46:9200/'\n",
    "    # uri_search = 'http://192.168.120.46:9200/test/articles/_search'\n",
    "    # uri_create = 'http://localhost:9200/test/articles/'\n",
    "\n",
    "    results = search(uri_search, \"_source\")\n",
    "    print(results)\n",
    "    # format_results(results)\n",
    "\n",
    "    #create_doc(uri_create, {\"content\": \"The fox!\"})\n",
    "    #results = search(uri_search, \"fox\")\n",
    "    #format_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !curl -XGET 192.168.120.46:9200/iperf3*/_search | jq >> sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "list_files = subprocess.run([\"ls\", \"-al\"])\n",
    "print(\"The exit code was: %d\" % list_files.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}